{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3945b39b",
   "metadata": {},
   "source": [
    "# Strands - Multiple MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000bd216",
   "metadata": {},
   "source": [
    "- `Strands Agent`에 대해 LLM에게 물어 본다면, 아직은 최신 프레임워크인 Strands에 대해 잘못된 답변을 합니다.\n",
    "- 이러한 이유로, \n",
    "    - MCP 1 : 웹 검색을 통해서 `Strands Agent`에 대한 정확한 데이터를 검색하도록 합니다. \n",
    "    - 검색 한 결과를 바탕으로 LLM은 상세 보고서를 작성 합니다. \n",
    "    - MCP 2 : 작성한 보고서를 `Notion` Page로 작성 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119c9294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from mcp import stdio_client, StdioServerParameters\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from strands.agent.conversation_manager import SlidingWindowConversationManager\n",
    "\n",
    "from strands import Agent\n",
    "from strands.tools.mcp import MCPClient\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b906611",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTION_API_KEY = os.environ.get(\"NOTION_API_KEY\")\n",
    "str_notion_mcp = \"{\\\"Authorization\\\": \\\"Bearer \" + NOTION_API_KEY + \"\\\", \\\"Notion-Version\\\": \\\"2022-06-28\\\" }\"\n",
    "EXA_API_KEY = os.environ.get(\"EXA_API_KEY\")\n",
    "TAVILY_API_KEY = os.environ.get(\"TAVILY_API_KEY\")\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 및 MCP 서버 경로 세팅\n",
    "MCP_SERVERS = {\n",
    "    \"thinking\" : {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-sequential-thinking\"],},  # thinking\n",
    "    \"duckduckgo\" : {\"command\": \"npx\", \"args\": [\"-y\", \"@pinkpixel/web-scout-mcp\"],},  # DuckDuckGo\n",
    "    \"tavily\" : {\"url\" : f\"https://mcp.tavily.com/mcp/?tavilyApiKey={TAVILY_API_KEY}\"},  # Tavily\n",
    "    \"notion\" : {\"command\": \"npx\", \"args\": [\"-y\", \"@notionhq/notion-mcp-server\"], \"env\": {\"OPENAPI_MCP_HEADERS\": str_notion_mcp, \"NOTION_PARENT_ID\":\"238e297222b8805c8cf1f0ff6ffda252\"}},\n",
    "    \"github\" : {\"command\": \"npx\", \"args\":[\"-y\", \"@modelcontextprotocol/server-github\"], \"env\": { \"GITHUB_TOKEN\": GITHUB_TOKEN }},  # github\n",
    "}\n",
    "\n",
    "\n",
    "MCP_SERVER_HTTP = {\"Notion\":  \"https://mcp.notion.com/mcp\",}\n",
    "\n",
    "\n",
    "\n",
    "conversation_manager = SlidingWindowConversationManager(window_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "724a9013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-y', '@pinkpixel/web-scout-mcp']\n",
      "https://mcp.tavily.com/mcp/?tavilyApiKey=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\n",
      "['-y', '@notionhq/notion-mcp-server']\n",
      "네, 최신 AI Agent 뉴스를 검색하고 요약한 후 Notion에 보고서를 작성해드리겠습니다.\n",
      "\n",
      "먼저 최신 AI Agent 뉴스를 검색하겠습니다.\n",
      "Tool #1: tavily_search\n",
      "이제 AI Agent 관련 최신 뉴스를 3개 찾았습니다. 각 뉴스의 상세 내용을 확인하기 위해 추가로 검색하겠습니다.\n",
      "Tool #2: tavily_extract\n",
      "이제 수집한 정보를 바탕으로 Notion에 보고서를 작성하겠습니다.\n",
      "Tool #3: API-post-page\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cycle failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/models/bedrock.py\", line 384, in _stream\n",
      "    response = self.client.converse_stream(**request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/botocore/client.py\", line 601, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/botocore/context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/botocore/client.py\", line 1074, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ThrottlingException: An error occurred (ThrottlingException) when calling the ConverseStream operation (reached max retries: 4): Too many tokens, please wait before trying again.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py\", line 215, in event_loop_cycle\n",
      "    async for event in events:\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py\", line 476, in _handle_tool_execution\n",
      "    async for event in events:\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py\", line 277, in recurse_event_loop\n",
      "    async for event in events:\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py\", line 172, in event_loop_cycle\n",
      "    raise e\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py\", line 132, in event_loop_cycle\n",
      "    async for event in stream_messages(agent.model, agent.system_prompt, agent.messages, tool_specs):\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/streaming.py\", line 318, in stream_messages\n",
      "    async for event in process_stream(chunks):\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/streaming.py\", line 273, in process_stream\n",
      "    async for chunk in chunks:\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/models/bedrock.py\", line 350, in stream\n",
      "    await task\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/opentelemetry/instrumentation/threading/__init__.py\", line 171, in wrapped_func\n",
      "    return original_func(*func_args, **func_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/sangjae/Dev/strands/venv/lib/python3.11/site-packages/strands/models/bedrock.py\", line 415, in _stream\n",
      "    raise ModelThrottledException(error_message) from e\n",
      "strands.types.exceptions.ModelThrottledException: An error occurred (ThrottlingException) when calling the ConverseStream operation (reached max retries: 4): Too many tokens, please wait before trying again.\n"
     ]
    },
    {
     "ename": "EventLoopException",
     "evalue": "An error occurred (ThrottlingException) when calling the ConverseStream operation (reached max retries: 4): Too many tokens, please wait before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mThrottlingException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/models/bedrock.py:384\u001b[39m, in \u001b[36mBedrockModel._stream\u001b[39m\u001b[34m(self, callback, messages, tool_specs, system_prompt)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverse_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/botocore/client.py:601\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/botocore/client.py:1074\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1073\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1075\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mThrottlingException\u001b[39m: An error occurred (ThrottlingException) when calling the ConverseStream operation (reached max retries: 4): Too many tokens, please wait before trying again.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModelThrottledException\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:215\u001b[39m, in \u001b[36mevent_loop_cycle\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    206\u001b[39m events = _handle_tool_execution(\n\u001b[32m    207\u001b[39m     stop_reason,\n\u001b[32m    208\u001b[39m     message,\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m     invocation_state=invocation_state,\n\u001b[32m    214\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:476\u001b[39m, in \u001b[36m_handle_tool_execution\u001b[39m\u001b[34m(stop_reason, message, agent, cycle_trace, cycle_span, cycle_start_time, invocation_state)\u001b[39m\n\u001b[32m    475\u001b[39m events = recurse_event_loop(agent=agent, invocation_state=invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:277\u001b[39m, in \u001b[36mrecurse_event_loop\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    276\u001b[39m events = event_loop_cycle(agent=agent, invocation_state=invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:172\u001b[39m, in \u001b[36mevent_loop_cycle\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mforce_stop\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mforce_stop_reason\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e)}}\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    174\u001b[39m logger.debug(\n\u001b[32m    175\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mretry_delay_seconds=<\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m>, max_attempts=<\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m>, current_attempt=<\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m> \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m| throttling exception encountered \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m     attempt + \u001b[32m1\u001b[39m,\n\u001b[32m    181\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:132\u001b[39m, in \u001b[36mevent_loop_cycle\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# TODO: To maintain backwards compatibility, we need to combine the stream event with invocation_state\u001b[39;00m\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m#       before yielding to the callback handler. This will be revisited when migrating to strongly\u001b[39;00m\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m#       typed events.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m stream_messages(agent.model, agent.system_prompt, agent.messages, tool_specs):\n\u001b[32m    133\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/streaming.py:318\u001b[39m, in \u001b[36mstream_messages\u001b[39m\u001b[34m(model, system_prompt, messages, tool_specs)\u001b[39m\n\u001b[32m    316\u001b[39m chunks = model.stream(messages, tool_specs \u001b[38;5;28;01mif\u001b[39;00m tool_specs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, system_prompt)\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m process_stream(chunks):\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/streaming.py:273\u001b[39m, in \u001b[36mprocess_stream\u001b[39m\u001b[34m(chunks)\u001b[39m\n\u001b[32m    271\u001b[39m metrics: Metrics = Metrics(latencyMs=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m: chunk}}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/models/bedrock.py:350\u001b[39m, in \u001b[36mBedrockModel.stream\u001b[39m\u001b[34m(self, messages, tool_specs, system_prompt, **kwargs)\u001b[39m\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m task\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001b[39m, in \u001b[36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001b[39m\u001b[34m(*func_args, **func_kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m     token = context.attach(otel_context)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/models/bedrock.py:415\u001b[39m, in \u001b[36mBedrockModel._stream\u001b[39m\u001b[34m(self, callback, messages, tool_specs, system_prompt)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.response[\u001b[33m\"\u001b[39m\u001b[33mError\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mThrottlingException\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ModelThrottledException(error_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(overflow_message \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;28;01mfor\u001b[39;00m overflow_message \u001b[38;5;129;01min\u001b[39;00m BEDROCK_CONTEXT_WINDOW_OVERFLOW_MESSAGES):\n",
      "\u001b[31mModelThrottledException\u001b[39m: An error occurred (ThrottlingException) when calling the ConverseStream operation (reached max retries: 4): Too many tokens, please wait before trying again.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mEventLoopException\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m all_tools = tools_0 + tools_1 \n\u001b[32m     26\u001b[39m agent = Agent(tools=all_tools, conversation_manager=conversation_manager)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m results = \u001b[43magent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/agent/agent.py:377\u001b[39m, in \u001b[36mAgent.__call__\u001b[39m\u001b[34m(self, prompt, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m    376\u001b[39m     future = executor.submit(execute)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001b[39m, in \u001b[36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001b[39m\u001b[34m(*func_args, **func_kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    170\u001b[39m     token = context.attach(otel_context)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/agent/agent.py:373\u001b[39m, in \u001b[36mAgent.__call__.<locals>.execute\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m() -> AgentResult:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:190\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/runners.py:118\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, coro, context)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._interrupt_count = \u001b[32m0\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._interrupt_count > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py:654\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future.done():\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m future.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/agent/agent.py:398\u001b[39m, in \u001b[36mAgent.invoke_async\u001b[39m\u001b[34m(self, prompt, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Process a natural language prompt through the agent's event loop.\u001b[39;00m\n\u001b[32m    381\u001b[39m \n\u001b[32m    382\u001b[39m \u001b[33;03mThis method implements the conversational interface (e.g., `agent(\"hello!\")`). It adds the user's prompt to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m \u001b[33;03m        - state: The final state of the event loop\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    397\u001b[39m events = \u001b[38;5;28mself\u001b[39m.stream_async(prompt, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    399\u001b[39m     _ = event\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(AgentResult, event[\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/agent/agent.py:508\u001b[39m, in \u001b[36mAgent.stream_async\u001b[39m\u001b[34m(self, prompt, **kwargs)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    507\u001b[39m     events = \u001b[38;5;28mself\u001b[39m._run_loop(message, invocation_state=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    509\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[32m    510\u001b[39m             callback_handler(**event[\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/agent/agent.py:544\u001b[39m, in \u001b[36mAgent._run_loop\u001b[39m\u001b[34m(self, message, invocation_state)\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;66;03m# Execute the event loop cycle with retry logic for context limits\u001b[39;00m\n\u001b[32m    543\u001b[39m events = \u001b[38;5;28mself\u001b[39m._execute_event_loop_cycle(invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    545\u001b[39m     \u001b[38;5;66;03m# Signal from the model provider that the message sent by the user should be redacted,\u001b[39;00m\n\u001b[32m    546\u001b[39m     \u001b[38;5;66;03m# likely due to a guardrail.\u001b[39;00m\n\u001b[32m    547\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    548\u001b[39m         event.get(\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    549\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    550\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mredactContent\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    551\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m event[\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mredactContent\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mredactUserContentMessage\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    552\u001b[39m     ):\n\u001b[32m    553\u001b[39m         \u001b[38;5;28mself\u001b[39m.messages[-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m    554\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: event[\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mevent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mredactContent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mredactUserContentMessage\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m    555\u001b[39m         ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/agent/agent.py:583\u001b[39m, in \u001b[36mAgent._execute_event_loop_cycle\u001b[39m\u001b[34m(self, invocation_state)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    578\u001b[39m     \u001b[38;5;66;03m# Execute the main event loop cycle\u001b[39;00m\n\u001b[32m    579\u001b[39m     events = event_loop_cycle(\n\u001b[32m    580\u001b[39m         agent=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    581\u001b[39m         invocation_state=invocation_state,\n\u001b[32m    582\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ContextWindowOverflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    587\u001b[39m     \u001b[38;5;66;03m# Try reducing the context size and retrying\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:215\u001b[39m, in \u001b[36mevent_loop_cycle\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_reason == \u001b[33m\"\u001b[39m\u001b[33mtool_use\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    205\u001b[39m     \u001b[38;5;66;03m# Handle tool execution\u001b[39;00m\n\u001b[32m    206\u001b[39m     events = _handle_tool_execution(\n\u001b[32m    207\u001b[39m         stop_reason,\n\u001b[32m    208\u001b[39m         message,\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m         invocation_state=invocation_state,\n\u001b[32m    214\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    216\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:476\u001b[39m, in \u001b[36m_handle_tool_execution\u001b[39m\u001b[34m(stop_reason, message, agent, cycle_trace, cycle_span, cycle_start_time, invocation_state)\u001b[39m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    475\u001b[39m events = recurse_event_loop(agent=agent, invocation_state=invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:277\u001b[39m, in \u001b[36mrecurse_event_loop\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}}\n\u001b[32m    276\u001b[39m events = event_loop_cycle(agent=agent, invocation_state=invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    280\u001b[39m recursive_trace.end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:215\u001b[39m, in \u001b[36mevent_loop_cycle\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_reason == \u001b[33m\"\u001b[39m\u001b[33mtool_use\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    205\u001b[39m     \u001b[38;5;66;03m# Handle tool execution\u001b[39;00m\n\u001b[32m    206\u001b[39m     events = _handle_tool_execution(\n\u001b[32m    207\u001b[39m         stop_reason,\n\u001b[32m    208\u001b[39m         message,\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m         invocation_state=invocation_state,\n\u001b[32m    214\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    216\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:476\u001b[39m, in \u001b[36m_handle_tool_execution\u001b[39m\u001b[34m(stop_reason, message, agent, cycle_trace, cycle_span, cycle_start_time, invocation_state)\u001b[39m\n\u001b[32m    473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    475\u001b[39m events = recurse_event_loop(agent=agent, invocation_state=invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:277\u001b[39m, in \u001b[36mrecurse_event_loop\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}}\n\u001b[32m    276\u001b[39m events = event_loop_cycle(agent=agent, invocation_state=invocation_state)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    280\u001b[39m recursive_trace.end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/strands/venv/lib/python3.11/site-packages/strands/event_loop/event_loop.py:245\u001b[39m, in \u001b[36mevent_loop_cycle\u001b[39m\u001b[34m(agent, invocation_state)\u001b[39m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mforce_stop\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mforce_stop_reason\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e)}}\n\u001b[32m    244\u001b[39m     logger.exception(\u001b[33m\"\u001b[39m\u001b[33mcycle failed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EventLoopException(e, invocation_state[\u001b[33m\"\u001b[39m\u001b[33mrequest_state\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: (stop_reason, message, agent.event_loop_metrics, invocation_state[\u001b[33m\"\u001b[39m\u001b[33mrequest_state\u001b[39m\u001b[33m\"\u001b[39m])}\n",
      "\u001b[31mEventLoopException\u001b[39m: An error occurred (ThrottlingException) when calling the ConverseStream operation (reached max retries: 4): Too many tokens, please wait before trying again."
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt = \"먼저, Strand Agent에 대해 인터넷 검색하고, 요약 해. 상세 보고서를 작성 해. 작성된 결과는 Notion의 새 페이지에 기록 해. 부모페이지 아이디는 238e297222b8805c8cf1f0ff6ffda252 야\"\n",
    "# prompt = \" Agent AI에 대해서, 간략히 요약하고 Notion 최상단 페이지를 하나 생성하여 요약 내용을 기록 해\"\n",
    "prompt = \"최신 AI Agent에 뉴스 3개만 검색하고, 요약해. 최종적으로 결과 보고서를 Notion에 작성해. 부모 페이지 아이디는 '238e297222b8805c8cf1f0ff6ffda252' 야. \"\n",
    "\n",
    "# config_duckduckgo = MCP_SERVERS[\"duckduckgo\"]\n",
    "# print(config_duckduckgo['args'])\n",
    "# mcp_duckduckgo = MCPClient(lambda: stdio_client(StdioServerParameters(command=config_duckduckgo['command'], args=config_duckduckgo['args'], env=config_duckduckgo.get(\"env\",None))))\n",
    "\n",
    "config_tavily = MCP_SERVERS[\"tavily\"]\n",
    "print(config_tavily['url'])\n",
    "mcp_tavily = MCPClient(lambda: streamablehttp_client(config_tavily['url']) )\n",
    "\n",
    "\n",
    "config_notion = MCP_SERVERS[\"notion\"]\n",
    "print(config_notion['args'])\n",
    "mcp_notion = MCPClient(lambda: stdio_client(StdioServerParameters(command=config_notion['command'], args=config_notion['args'], env=config_notion.get(\"env\",None))))\n",
    "\n",
    "\n",
    "# with mcp_duckduckgo, mcp_notion:\n",
    "with mcp_tavily, mcp_notion:\n",
    "    # tools_0 = mcp_duckduckgo.list_tools_sync()\n",
    "    tools_0 = mcp_tavily.list_tools_sync()\n",
    "    tools_1 = mcp_notion.list_tools_sync()\n",
    "    all_tools = tools_0 + tools_1 \n",
    "    \n",
    "    agent = Agent(tools=all_tools, conversation_manager=conversation_manager)\n",
    "    results = agent(prompt)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fbd1850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'role': 'user', 'content': [{'text': \"최신 AI Agent에 뉴스 3개만 검색하고, 요약해. 최종적으로 결과 보고서를 Notion에 작성해. 부모 페이지 아이디는 '238e297222b8805c8cf1f0ff6ffda252' 야. \"}]}\n",
      "1 {'role': 'assistant', 'content': [{'text': '네, 최신 AI Agent 뉴스를 검색하고 요약해서 Notion에 보고서를 작성해드리겠습니다.\\n\\n먼저 최신 AI Agent 뉴스를 검색하겠습니다.'}, {'toolUse': {'toolUseId': 'tooluse__nQtfgu-TPSimc8L6tI1vg', 'name': 'DuckDuckGoWebSearch', 'input': {'query': 'AI Agent 최신 뉴스 2024', 'maxResults': 3}}}]}\n",
      "2 {'role': 'user', 'content': [{'toolResult': {'status': 'success', 'toolUseId': 'tooluse__nQtfgu-TPSimc8L6tI1vg', 'content': [{'text': 'Found 3 search results:\\n\\n1. \"내년 Ai 에이전트 보급 원년 될 것…1000건 이상 예약 대기 중\"\\n   URL: https://www.hankyung.com/article/2024120934951\\n   Summary: \"내년 AI 에이전트 보급 원년 될 것…1000건 이상 예약 대기 중\", 가트너 2025 10대 전략기술 동향 주목할 기술 1위로 \\'AI 에이전트\\' 업무 자동화, 생산성 ...\\n\\n2. Ms \"Ai 에이전트 시대 연다\"…새로운 Ai 기능 대거 공개 (종합) | 연합뉴스\\n   URL: https://www.yna.co.kr/view/AKR20241119147151091\\n   Summary: MS는 이날 미국 시카고에서 연례 최대 플래그십 콘퍼런스 \\'이그나이트 2024\\'를 열고 AI 기반 작업 도우미인 마이크로소프트 365 코파일럿의 신규 AI 에이전트와 기능, 자율 에이전트 (autonomous agents) 등을 대거 선보였다.\\n\\n3. [신년 특집] 2024년 지켜볼 8가지 Ai 이슈 (1)... Ai 에이전트, 어디까지 진화할까 - Ai타임스\\n   URL: https://www.aitimes.com/news/articleView.html?idxno=156206\\n   Summary: 온디바이스 AI, 제2의 엔비디아 붐 일어날까 2023년 생성 AI 시장은 클라우드를 기반으로 발전했다. 이 때문에 서버용 AI 칩을 생산하는 엔비디아가 대박을 기록했다. 이제 GPU는 없어서 못 팔 정도가 됐다. 하지만 2024년 생성 AI는 상업적인 보편화 과정을 거치며 온디바이스 AI 기술로 발전해 나갈 것으로 ...\\n'}]}}]}\n",
      "3 {'role': 'assistant', 'content': [{'text': '이제 각 뉴스 기사의 자세한 내용을 확인해보겠습니다.'}, {'toolUse': {'toolUseId': 'tooluse_FrOuNM0VRyy5rEZdd-gtIA', 'name': 'UrlContentExtractor', 'input': {'url': '[\"https://www.hankyung.com/article/2024120934951\", \"https://www.yna.co.kr/view/AKR20241119147151091\", \"https://www.aitimes.com/news/articleView.html?idxno=156206\"]'}}}]}\n",
      "4 {'role': 'user', 'content': [{'toolResult': {'status': 'success', 'toolUseId': 'tooluse_FrOuNM0VRyy5rEZdd-gtIA', 'content': [{'text': 'Error: An unexpected error occurred while fetching the webpage (Invalid URL)'}]}}]}\n",
      "5 {'role': 'assistant', 'content': [{'text': 'URL을 하나씩 확인해보겠습니다.'}, {'toolUse': {'toolUseId': 'tooluse_F4d8AiqcQz6fCmFtBQbngw', 'name': 'UrlContentExtractor', 'input': {'url': 'https://www.hankyung.com/article/2024120934951'}}}]}\n",
      "6 {'role': 'user', 'content': [{'toolResult': {'status': 'success', 'toolUseId': 'tooluse_F4d8AiqcQz6fCmFtBQbngw', 'content': [{'text': ''}]}}]}\n",
      "7 {'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_mpIn7zfVTC-TquU6tpjaCA', 'name': 'UrlContentExtractor', 'input': {'url': 'https://www.yna.co.kr/view/AKR20241119147151091'}}}]}\n",
      "8 {'role': 'user', 'content': [{'toolResult': {'status': 'success', 'toolUseId': 'tooluse_mpIn7zfVTC-TquU6tpjaCA', 'content': [{'text': 'MS \"AI 에이전트 시대 연다\"…새로운 AI 기능 대거 공개(종합) | 연합뉴스 연합뉴스 본문 바로가기 메뉴 바로가기 광고 새로운 연합뉴스를 만나세요 회원이 되시면 뉴스가 특별해집니다. 닫기 국가기간뉴스 통신사 연합뉴스 국가기간뉴스 통신사 연합뉴스 마이페이지 로그인 검색창 열기 메뉴 열기 국가기간뉴스 통신사 연합뉴스 국가기간뉴스 통신사 연합뉴스 MS \"AI 에이전트 시대 연다\"…새로운 AI 기능 대거 공개(종합) 북마크 공유 댓글 글자크기 프린트 제보 마이페이지 로그인 검색창 열기 메뉴 열기 광고 광고 美 시카고서 연례 플래그십 콘퍼런스 \\'이그나이트\\' 개최데이터센터에 자체 제작 DPU 탑재…클라우드 연결 PC도 소개 이미지 확대 마이크로소프트 사티아 나델라 CEO 기조 연설 [시카고=AP 연합뉴스] (샌프란시스코=연합뉴스) 김태종 특파원 = 챗GPT 개발사 오픈AI와 함께 인공지능(AI) 열풍을 주도하고 있는 마이크로소프트(MS)가 19일(현지시간) \"AI 에이전트 시대를 열겠다\"고 밝히며 새로운 기능을 공개했다. MS는 이날 미국 시카고에서 연례 최대 플래그십 콘퍼런스 \\'이그나이트 2024\\'를 열고 AI 기반 작업 도우미인 마이크로소프트 365 코파일럿의 신규 AI 에이전트와 기능, 자율 에이전트(autonomous agents) 등을 대거 선보였다. 사티아 나델라 MS 최고경영자(CEO)는 이날 개막 연설에서 \"코파일럿은 AI를 위한 UI(사용자 인터페이스)로, 앞으로 모든 직원은 자신을 알고 자신의 업무 방식을 이해하는 코파일럿을 가지게 될 것\"이라고 말했다. 2000년대 이전 PC 운영체제 윈도를 앞세워 일상의 업무 방식에 혁신을 가져온 MS가 이제 AI가 스스로 업무를 처리하는 AI 에인전트 시대를 열며 업무 방식에 또다른 변화를 주도하겠다는 것이다. MS는 이날 화상 회의 중 이용자의 목소리를 실시간으로 학습해 9개 언어로 통역해 주는 \\'통역 에이전트\\' 등 다양한 AI 에이전트를 공개했다. 특정 사이트나 파일, 폴더가 있는 곳을 쉽게 찾아주는 \\'셰어포인트 에이전트\\', 직원들이 휴가 신청을 하고 급여 및 복지 정보를 대신 확인해 주는 \\'직원 셀프 서비스 에이전트\\'도 소개됐다. MS는 지난달 발표했던 \\'코파일럿 스튜디오\\'에서 맞춤형 \\'자율 에이전트\\'를 구축할 수 있는 기능도 이날부터 미리보기 형태로 공개한다고 밝혔다. \\'코파일럿 스튜디오\\'는 MS의 AI 모델 코파일럿을 이용해 사용자가 직접 AI 에이전트를 만들고 관리할 수 있는 MS의 AI 기반 플랫폼이다. 이용자는 이를 통해 복잡한 업무를 처리하는 자율 에이전트를 직접 구축할 수 있고, 일일이 프롬프트를 입력할 필요 없이 다양한 업무를 효율화할 수 있다. 다양한 에이전트가 들어 있는 \\'에이전트 라이브러리\\'(Agent library)를 활용해 상황에 따라 반복적인 작업을 수행할 수 있는 에이전트를 구축할 수도 있다. 나델라 CEO는 \"때때로 우리는 이런 에이전트를 구축하는 데 많은 노력이 필요한 것으로 신비롭게 여기지만, 우리의 비전은 이를 워드 문서를 만드는 것만큼 간단하게 만드는 것\"이라고 강조했다. 이미지 확대 마이크로소프트 로고 [AFP 연합뉴스 자료사진. 재판매 및 DB 금지] 엑셀과 파워포인트 등 소프트웨어에 적용돼 단순 반복 작업을 해결해주는 AI 기능도 소개됐다. 파워포인트에는 AI가 문서에서 중요 포인트를 집어내 이를 차트·애니메이션 등이 적용된 슬라이드로 제작해주는 \\'내러티브 빌더\\', 엑셀에는 제목·수식 등 시각적 요소를 이용자 맞춤형으로 만들어주는 \\'새로운 시작\\' 기능이 추가됐다. 화상회의 업무 툴 \\'팀즈\\'에는 참가자가 공유한 화면 속 차트·문서·그림 등을 분석해 중요한 논의 사항까지도 기록하는 기능이 추가됐다. 또 이용자들이 클라우드의 프로그램 및 파일에 연결해 사용할 수 있는 새로운 PC인 \\'윈도 365 클라우드 링크\\'도 선보였다. 보안이 강화된 이 PC는 내년 4월 일부 시장에서 349달러에 판매된다. MS는 이와 함께 데이터 센터에 사용되는 칩으로 자체 제작한 \\'애저 통합 HSM\\'과 데이터처리장치(DPU)인 \\'애저 부스트 DPU\\'를 탑재할 예정이라고 설명했다. \\'애저 통합 HSM\\' 보안 강화 목적의 칩이고, DPU는 데이터입출력을 보조하는 칩이다. 그동안 아마존과 MS, 구글 등 주요 클라우드 업체는 ARM 기반 저전력 중앙처리장치(CPU)와 AI 가속기 등을 자체 설계해 사용해 왔다. 고대역폭 메모리(HBM)를 적용해 하나의 슈퍼컴퓨터를 가상의 여러 PC로 나눠 사용하는 가상머신 \\'HBv5\\'도 소개했다. MS는 HBM 적용 등으로 \\'HBv5\\'가 경쟁 서비스 대비 최대 8배 높은 성능을 제공한다고 설명했다. MS는 \"포춘 500대 기업의 약 70%가 MS 365 코파일럿을 통해 생산성을 높이고 있다\"며 \"맞춤형 AI 에이전트 경험 확장을 통해 AI 에이전트의 시대를 열어 나가겠다\"고 밝혔다. taejong75@yna.co.kr 제보는 카카오톡 okjebo <저작권자(c) 연합뉴스, 무단 전재-재배포, AI 학습 및 활용 금지> 2024/11/20 04:46 송고 2024년11월20일 04시46분 송고 #에이전트 #AI #기능 댓글 좋아요 슬퍼요 화나요 후속요청 국내 최대 원스톱 콘텐츠 제공 플랫폼 함께 보면 좋은 콘텐츠 by 데이블 광고 함께 읽기 좋은 콘텐츠 Taboola 후원링크 광고 광고 광고 연합 마이뉴스 다양한 주제별 맞춤 추천 뉴스를 제공합니다. 북마크 공유 공유하기 카카오톡 페이스북 X 페이스북 메신저 네이버 밴드 URL 복사 닫기 URL이 복사되었습니다. 댓글 글자크기 본문 글자 크기 조정 폰트 1단계 13px 폰트 2단계 16px 폰트 3단계 18px 폰트 4단계 20px 폰트 5단계 22px 닫기 프린트 제보 광고 광고 산사태로 통째 꺼진 산청 상능마을…이장 6분전 방송, 주민 탈출 생일잔치 열어준 아들 왜 쐈을까…추궁에도 \"알려고 하지마\" 日서 병원치료 후 한달 연락 끊긴 20대 한국 여성, 안전 확인돼 타정총 공포탄 수백발 소지하고 국회 들어가던 80대 검거 검찰, \\'쯔양 공갈 혐의\\' 구제역 항소심도 징역 4년 구형 \"허황되고 유치한 스토리 안돼\"…中 \\'국뽕 항일 웹드라마\\' 단속 여수 해상서 40대 여성 시신 발견…해경 사인 조사 태안서 조업 중 실종 70대 선원…신진항 해안가서 숨진 채 발견 이전 콘텐츠 다음 콘텐츠 광고 광고 [영상] \"이건 학대\"…털 박박 깎인채 7시간만에 파양된 2살 유기견 [영상] \"학생들 불붙은채 몸부림\"…방글라공군기, 이륙직후 학교로 추락 [영상] 집안 반대 연애결혼했다고 탕!…파키스탄 또 \\'명예살인\\' 논란 이전 콘텐츠 다음 콘텐츠 가평·산청·서산·예산·담양·합천, 특별재난지역 선포 李대통령, 강선우 청문보고서 재송부 요청…금주 내 임명할 듯 소비쿠폰 이틀째도 열기…\\'오픈런\\'에 \\'전산 먹통\\' 불편 잇달아 내란특검, \\'언론사 단전·단수 의혹\\' 이상민 전 장관 25일 소환 이전 콘텐츠 다음 콘텐츠 광고 광고 광고 함께 보면 좋은 콘텐츠 by 데이블 광고 광고 랭킹뉴스 많이 본 뉴스 공감 많은 뉴스 더보기 더보기 광고 함께 읽기 좋은 콘텐츠 by 데이블 광고 연합뉴스 Games 함께 보면 좋은 콘텐츠 Taboola 후원링크 [영상] \"정말 오래 참았습니다\"…\\'침묵\\' 깬 양양군민들의 분노 [영상] \"맨홀에 사람이\" 급류 뛰어든 사장님, \\'맨몸 방벽\\' 친 직원들 [영상] 점박이 아빠가 보디빌딩 대회 나간 사연 [BlaccTV] \"보험 부르겠다\"더니 현장 떠나…500m 추격해 붙잡은 트럭 기사 이전 콘텐츠 다음 콘텐츠 함께 볼만한 콘텐츠 by 데이블 광고 광고 뉴스 검색어 입력 양식 통합 검색 삭제 검색 전체메뉴 닫기 뉴스 최신뉴스 정치 메뉴 열기/닫기 정치전체 대통령실/총리실 국회/정당 외교 국방 북한 메뉴 열기/닫기 북한전체 학술/연구 북한 알아보기 인물 비주얼 NK NOW 경제 메뉴 열기/닫기 경제전체 경제/정책 금융 부동산 취업/창업 소비자 마켓+ 메뉴 열기/닫기 마켓+전체 국내주식 해외주식 채권 펀드/ETF 글로벌시장 증권/운용사 리포트 공시 산업 메뉴 열기/닫기 산업전체 산업/기업 전기전자 중화학 자동차 건설 에너지/자원 IT/과학 게임 유통/서비스 중기/벤처 바이오/헬스 농림축산 해양수산 사회 메뉴 열기/닫기 사회전체 사건/사고 법원/검찰 교육 복지/노동 환경/기후변화 여성/아동 재외동포 다문화 전국 메뉴 열기/닫기 전국전체 경기 인천 부산 울산 경남 대구/경북 광주/전남 전북 대전/충남/세종 충북 강원 제주 세계 메뉴 열기/닫기 세계전체 특파원 미국/북미 중국 일본 아시아/호주 유럽 중남미 중동/아프리카 국제기구 문화 메뉴 열기/닫기 문화전체 책/문학 만화/웹툰 종교 공연/전시 학술/문화재 미디어 여행/레저 생활 건강 메뉴 열기/닫기 건강전체 헬스노트 위클리 건강 더건강 영상 연예 메뉴 열기/닫기 연예전체 방송 영화 가요 해외연예 스포츠 메뉴 열기/닫기 스포츠전체 야구 축구 농구/배구 골프 오피니언 사람들 메뉴 열기/닫기 사람들전체 인사 부고 동정/게시판 CEO 인터뷰 뉴스+ 메뉴 열기/닫기 브랜드뉴스 이슈 팩트체크 이 시각 헤드라인 비주얼뉴스 메뉴 열기/닫기 영상 포토 화보 그래픽 D스토리 테마별뉴스 메뉴 열기/닫기 핫뉴스 주요뉴스 긴급뉴스 단독뉴스 많이 본 뉴스 오래 머문 뉴스 공감 많은 뉴스 외국어 뉴스 English 中文 日本語 عربي Español Français 뉴스상품 프리미엄뉴스 뉴스리더 인터넷맞춤형 보도자료 해외배포 보도자료 국내배포 광고안내 KTX 고속열차 SRT 고속열차 AREX 공항철도 모바일 PC 출판물 LED전광판 사업제휴 콘텐츠판매 보도사진 그래픽 동영상 인물 출판물 이매진 연합연감 영문연감 단행본 월간 마이더스 서비스안내 서비스 소개 모바일앱 안내 재난포털 날씨 기자 뉴스레터 제보 뉴스상품 광고안내 콘텐츠판매 연합뉴스 Games 서비스 문의 서비스 문의 서비스 문의 자주 묻는 질문 공지사항 1:1 문의 계약사/제휴문의 SNS 다양한 채널에서 연합뉴스를 만나보세요! 연합뉴스 페이스북 연합뉴스 인스타그램 연합뉴스 유튜브 연합뉴스 트위터 화면 상단으로 이동 뉴스레터 연합뉴스 Games APP설치 뉴스 최신뉴스 정치 메뉴 열기/닫기 정치전체 대통령실/총리실 국회/정당 외교 국방 북한 메뉴 열기/닫기 북한전체 학술/연구 북한 알아보기 인물 비주얼 NK NOW 경제 메뉴 열기/닫기 경제전체 경제/정책 금융 부동산 취업/창업 소비자 마켓+ 메뉴 열기/닫기 마켓+전체 국내주식 해외주식 채권 펀드/ETF 글로벌시장 증권/운용사 리포트 공시 산업 메뉴 열기/닫기 산업전체 산업/기업 전기전자 중화학 자동차 건설 에너지/자원 IT/과학 게임 유통/서비스 중기/벤처 바이오/헬스 농림축산 해양수산 사회 메뉴 열기/닫기 사회전체 사건/사고 법원/검찰 교육 복지/노동 환경/기후변화 여성/아동 재외동포 다문화 전국 메뉴 열기/닫기 전국전체 경기 인천 부산 울산 경남 대구/경북 광주/전남 전북 대전/충남/세종 충북 강원 제주 세계 메뉴 열기/닫기 세계전체 특파원 미국/북미 중국 일본 아시아/호주 유럽 중남미 중동/아프리카 국제기구 문화 메뉴 열기/닫기 문화전체 책/문학 만화/웹툰 종교 공연/전시 학술/문화재 미디어 여행/레저 생활 건강 메뉴 열기/닫기 건강전체 헬스노트 위클리 건강 더건강 영상 연예 메뉴 열기/닫기 연예전체 방송 영화 가요 해외연예 스포츠 메뉴 열기/닫기 스포츠전체 야구 축구 농구/배구 골프 오피니언 사람들 메뉴 열기/닫기 사람들전체 인사 부고 동정/게시판 CEO 인터뷰 뉴스+ 메뉴 열기/닫기 브랜드뉴스 이슈 팩트체크 이 시각 헤드라인 비주얼뉴스 메뉴 열기/닫기 영상 포토 화보 그래픽 D스토리 테마별뉴스 메뉴 열기/닫기 핫뉴스 주요뉴스 긴급뉴스 단독뉴스 많이 본 뉴스 오래 머문 뉴스 공감 많은 뉴스 외국어 뉴스 English 中文 日本語 عربي Español Français 뉴스상품 프리미엄뉴스 뉴스리더 인터넷맞춤형 보도자료 해외배포 보도자료 국내배포 광고안내 KTX 고속열차 SRT 고속열차 AREX 공항철도 모바일 PC 출판물 LED전광판 사업제휴 콘텐츠판매 보도사진 그래픽 동영상 인물 출판물 이매진 연합연감 영문연감 단행본 월간 마이더스 서비스안내 서비스 소개 모바일앱 안내 재난포털 날씨 기자 뉴스레터 제보 뉴스상품 광고안내 콘텐츠판매 연합뉴스 Games 서비스 문의 서비스 문의 서비스 문의 자주 묻는 질문 공지사항 1:1 문의 계약사/제휴문의 English 中文 日文 عربي Español Français 유튜브 채널 연합뉴스 통통컬처 통통테크 더건강 KOREA NOW NK NOW K-VIBE SNS 다양한 채널에서 연합뉴스를 만나보세요! 연합뉴스 페이스북 연합뉴스 인스타그램 연합뉴스 유튜브 연합뉴스 트위터 회사소개 윤리헌장 저작권규약 수용자권익위원회 고충처리 독자게시판 제보 보도자료 서비스 문의 RSS 사이트맵 이미지 확대 마이크로소프트 사티아 나델라 CEO 기조 연설 [시카고=AP 연합뉴스] 2024-11-20 04:28 이미지 확대 마이크로소프트 로고 [AFP 연합뉴스 자료사진. 재판매 및 DB 금지] 2024-11-20 04:26 이전 콘텐츠 다음 콘텐츠 메뉴 열기/닫기 이전 콘텐츠 다음 콘텐츠 본문으로 돌아가기 광고 광고삭제 광고 광고삭제 댓글 닫기'}]}}]}\n",
      "9 {'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_Y7jo2JUXRPi1HpJzEO_K6g', 'name': 'UrlContentExtractor', 'input': {'url': 'https://www.aitimes.com/news/articleView.html?idxno=156206'}}}]}\n",
      "10 {'role': 'user', 'content': [{'toolResult': {'status': 'error', 'toolUseId': 'tooluse_Y7jo2JUXRPi1HpJzEO_K6g', 'content': [{'text': 'The tool result was too large!'}]}}]}\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(agent.messages):\n",
    "    print(i,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ac513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30771e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d53a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b234b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 최신 AI Agent와 특히 Strand Agent에 대한 상세 보고서를 작성해 드리겠습니다. 먼저 관련 정보를 검색하고 분석해 보겠습니다.\n",
      "Tool #1: DuckDuckGoWebSearch\n",
      "제공된 검색 결과에 Strand Agents에 관한 더 자세한 정보를 확인하기 위해 추가 검색을 진행하겠습니다.\n",
      "Tool #2: DuckDuckGoWebSearch\n",
      "더 자세한 기술적 정보와 사용법을 알아보기 위해 몇 가지 페이지의 내용을 추출하겠습니다.\n",
      "Tool #3: UrlContentExtractor\n",
      "\n",
      "Tool #4: UrlContentExtractor\n",
      "\n",
      "Tool #5: UrlContentExtractor\n",
      "\n",
      "Tool #6: UrlContentExtractor\n",
      "\n",
      "Tool #7: sequentialthinking\n",
      "\n",
      "Tool #8: sequentialthinking\n",
      "\n",
      "Tool #9: sequentialthinking\n",
      "\n",
      "Tool #10: sequentialthinking\n",
      "\n",
      "Tool #11: sequentialthinking\n",
      "\n",
      "Tool #12: sequentialthinking\n",
      "\n",
      "Tool #13: sequentialthinking\n",
      "\n",
      "Tool #14: sequentialthinking\n",
      "# 최신 AI Agent와 Strand Agents 상세 보고서\n",
      "\n",
      "## 1. AI 에이전트(Agent)의 개념과 배경\n",
      "\n",
      "AI 에이전트는 사용자의 목표를 달성하기 위해 데이터를 분석하고, 스스로 판단하며, 실제 행동을 수행하는 자율적 인공지능 시스템입니다. 기존의 생성형 AI가 콘텐츠 생성에 집중했다면, AI 에이전트는 문제 해결과 작업 실행까지 포괄합니다. \n",
      "\n",
      "**핵심 특징:**\n",
      "- **자율성**: 인간의 개입 없이도 작업을 완료할 수 있는 능력\n",
      "- **추론 및 계획 능력**: 복잡한 문제에 대한 단계별 접근 가능\n",
      "- **도구 사용 능력**: 다양한 외부 도구와 API를 활용하여 작업 수행\n",
      "\n",
      "최근 몇 년간 LLM(대규모 언어 모델)의 발전으로 인해 AI 에이전트 기술도 크게 발전했으며, 특히 ReAct(Reasoning and Acting) 논문 이후로 LLM이 추론하고, 계획하며, 환경에서 행동을 취할 수 있게 되었습니다.\n",
      "\n",
      "## 2. Strands Agents 소개\n",
      "\n",
      "Strands Agents는 AWS에서 출시한 오픈 소스 AI Agent SDK로, 모델 중심(model-driven) 접근 방식을 사용해 코드 몇 줄만으로 AI 에이전트를 구축하고 실행할 수 있게 해줍니다. 이미 Amazon Q Developer, AWS Glue, VPC Reachability Analyzer 등 여러 AWS 내부 팀에서 Strands Agents를 프로덕션에 사용하고 있습니다.\n",
      "\n",
      "### 핵심 구성 요소\n",
      "\n",
      "Strands Agents에서 AI 에이전트는 세 가지 핵심 요소로 구성됩니다:\n",
      "\n",
      "1. **모델(Model)**: 에이전트의 '두뇌' 역할을 하는 LLM\n",
      "   - Amazon Bedrock, Anthropic, Ollama, Meta 등 다양한 제공업체 모델 지원\n",
      "   - 추론 및 도구 사용 기능을 갖춘 모델 활용\n",
      "\n",
      "2. **도구(Tools)**: 에이전트가 작업을 수행하기 위해 사용하는 기능들\n",
      "   - Model Context Protocol(MCP) 서버를 통해 수천 개의 기존 도구 제공\n",
      "   - 파일 조작, API 요청, AWS API 상호작용 등을 위한 20개 이상의 사전 구축 도구\n",
      "   - Python 함수를 `@tool` 데코레이터로 쉽게 도구화 가능\n",
      "\n",
      "3. **프롬프트(Prompt)**: 에이전트에게 주어지는 작업을 정의하는 자연어 지시문\n",
      "   - 일반 프롬프트: 최종 사용자의 질문이나 작업 요청\n",
      "   - 시스템 프롬프트: 에이전트의 일반적인 행동 및 지침 정의\n",
      "\n",
      "### Agentic Loop (에이전트 루프)\n",
      "\n",
      "Strands의 핵심은 '에이전틱 루프(agentic loop)'라는 반복 과정으로, 이 과정에서 에이전트는 모델과 도구를 사용하여 주어진 작업을 완료합니다:\n",
      "\n",
      "1. LLM에 프롬프트와 에이전트 컨텍스트, 도구 설명을 제공\n",
      "2. LLM은 자연어로 응답하거나, 단계를 계획하거나, 이전 단계에 반성하거나, 도구를 선택\n",
      "3. LLM이 도구를 선택하면 Strands가 이를 실행하고 결과를 LLM에 다시 제공\n",
      "4. LLM이 작업을 완료할 때까지 이 과정 반복\n",
      "\n",
      "## 3. Strands Agents의 주요 특징과 기능\n",
      "\n",
      "1. **경량 및 유연한 설계**\n",
      "   - 간단하면서도 완전히 사용자 정의 가능한 에이전트 루프\n",
      "   - 복잡한 오케스트레이션 없이도 효과적인 에이전트 구현\n",
      "\n",
      "2. **모델 독립적(Model Agnostic)**\n",
      "   - Amazon Bedrock, Anthropic, LiteLLM, Llama, Ollama, OpenAI, Writer 등 지원\n",
      "   - 사용자 정의 모델 제공업체 구현 가능\n",
      "\n",
      "3. **고급 기능**\n",
      "   - 다중 에이전트 시스템: 여러 에이전트 간 협업 가능\n",
      "   - 자율 에이전트: 최소한의 인간 개입으로 복잡한 작업 수행\n",
      "   - 스트리밍 지원: 실시간 응답 처리\n",
      "\n",
      "4. **내장 MCP(Model Context Protocol)**\n",
      "   - MCP 서버에 대한 네이티브 지원\n",
      "   - 수천 개의 미리 구축된 도구에 접근 가능\n",
      "\n",
      "5. **AWS 서비스 통합**\n",
      "   - Amazon Bedrock, AWS Lambda, AWS Step Functions 등과 원활한 연결\n",
      "   - AWS 인프라를 기반으로 한 조직에 최적화\n",
      "\n",
      "6. **멀티모달 기능**\n",
      "   - 텍스트, 음성, 이미지 처리 등 여러 모달리티 지원\n",
      "\n",
      "7. **풍부한 도구 생태계**\n",
      "   - AWS 서비스 상호 작용을 위한 다양한 도구 세트\n",
      "   - 사용자 정의 도구 확장성\n",
      "\n",
      "## 4. Strands Agents의 장단점\n",
      "\n",
      "### 장점\n",
      "\n",
      "1. **단순성과 빠른 개발**\n",
      "   - 복잡한 오케스트레이션 코드 없이 몇 줄의 코드만으로 에이전트 구축\n",
      "   - 개발 시간 대폭 단축 (몇 달에서 며칠/몇 주로)\n",
      "\n",
      "2. **유연성**\n",
      "   - 다양한 LLM과 도구를 지원하여 다양한 사용 사례에 적용 가능\n",
      "   - 사용자 정의 도구 및 모델 제공업체 구현 가능\n",
      "\n",
      "3. **확장성**\n",
      "   - 간단한 대화형 어시스턴트부터 복잡한 자율 워크플로우까지 확장\n",
      "   - 로컬 개발에서 프로덕션 배포까지 지원\n",
      "\n",
      "4. **최신 모델의 능력 활용**\n",
      "   - 최신 LLM의 발전된 추론 및 도구 사용 능력 최대한 활용\n",
      "   - 모델의 자연적인 추론 능력에 의존하여 복잡한 코딩 감소\n",
      "\n",
      "5. **AWS 서비스 통합**\n",
      "   - AWS 인프라 기반 조직에 원활한 통합 제공\n",
      "   - 기존 AWS 리소스와의 효율적인 연동\n",
      "\n",
      "6. **오픈 소스**\n",
      "   - 커뮤니티 기반 개발과 지원\n",
      "   - 필요에 따른 맞춤 설정 가능\n",
      "\n",
      "### 단점\n",
      "\n",
      "1. **모델 의존성**\n",
      "   - 모델 중심 접근 방식은 사용하는 LLM의 능력에 크게 의존\n",
      "   - 모델 품질이 낮으면 에이전트 성능도 제한될 수 있음\n",
      "\n",
      "2. **AWS 친화적 설계**\n",
      "   - AWS 서비스와의 통합에 초점\n",
      "   - 다른 클라우드 제공업체 사용 조직에서는 일부 기능 활용 제한\n",
      "\n",
      "3. **복잡한 작업의 신뢰성**\n",
      "   - 매우 복잡한 작업의 경우, 모델 중심 접근이 전통적 워크플로우보다 예측 가능성 낮을 수 있음\n",
      "   - 결정적인 결과가 필요한 경우 추가 검증 필요\n",
      "\n",
      "4. **학습 곡선**\n",
      "   - 기존 프레임워크에서 전환하는 개발자들에게 새로운 패러다임 학습 필요\n",
      "\n",
      "## 5. Strands Agents 사용 방법\n",
      "\n",
      "### 설치\n",
      "\n",
      "```bash\n",
      "# 가상 환경 생성 및 활성화\n",
      "python -m venv .venv\n",
      "source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n",
      "\n",
      "# Strands 및 도구 설치\n",
      "pip install strands-agents strands-agents-tools\n",
      "```\n",
      "\n",
      "### 기본 사용법\n",
      "\n",
      "```python\n",
      "from strands import Agent\n",
      "from strands_tools import calculator\n",
      "\n",
      "# 기본 에이전트 생성 (기본적으로 Amazon Bedrock의 Claude 4 Sonnet 모델 사용)\n",
      "agent = Agent(tools=[calculator])\n",
      "\n",
      "# 에이전트에게 질문하기\n",
      "response = agent(\"What is the square root of 1764\")\n",
      "```\n",
      "\n",
      "### 파이썬 기반 도구 생성\n",
      "\n",
      "```python\n",
      "from strands import Agent, tool\n",
      "\n",
      "@tool\n",
      "def word_count(text: str) -> int:\n",
      "    \"\"\"Count words in text.\n",
      "    This docstring is used by the LLM to understand the tool's purpose.\n",
      "    \"\"\"\n",
      "    return len(text.split())\n",
      "\n",
      "agent = Agent(tools=[word_count])\n",
      "response = agent(\"How many words are in this sentence?\")\n",
      "```\n",
      "\n",
      "### 다양한 모델 제공업체 사용\n",
      "\n",
      "```python\n",
      "# Bedrock\n",
      "from strands.models import BedrockModel\n",
      "bedrock_model = BedrockModel(\n",
      "    model_id=\"us.amazon.nova-pro-v1:0\",\n",
      "    temperature=0.3,\n",
      "    streaming=True,  # 스트리밍 활성화/비활성화\n",
      ")\n",
      "agent = Agent(model=bedrock_model)\n",
      "\n",
      "# Ollama (로컬 개발용)\n",
      "from strands.models.ollama import OllamaModel\n",
      "ollama_model = OllamaModel(\n",
      "    host=\"http://localhost:11434\",\n",
      "    model_id=\"llama3\"\n",
      ")\n",
      "agent = Agent(model=ollama_model)\n",
      "\n",
      "# Llama API\n",
      "from strands.models.llamaapi import LlamaAPIModel\n",
      "llama_model = LlamaAPIModel(\n",
      "    model_id=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
      ")\n",
      "agent = Agent(model=llama_model)\n",
      "\n",
      "# Cohere (OpenAI 호환성 레이어 사용)\n",
      "from strands.models.openai import OpenAIModel\n",
      "model = OpenAIModel(\n",
      "    client_args={\n",
      "        \"api_key\": \"<COHERE_API_KEY>\",\n",
      "        \"base_url\": \"https://api.cohere.ai/compatibility/v1\",\n",
      "        # Cohere 호환성 엔드포인트\n",
      "    },\n",
      "    model_id=\"command-a-03-2025\",\n",
      "    params={\n",
      "        \"stream_options\": None\n",
      "    }\n",
      ")\n",
      "agent = Agent(model=model)\n",
      "```\n",
      "\n",
      "### MCP 서버 통합\n",
      "\n",
      "```python\n",
      "from strands import Agent\n",
      "from strands.tools.mcp import MCPClient\n",
      "from mcp import stdio_client, StdioServerParameters\n",
      "\n",
      "# AWS 문서에 접근하는 MCP 클라이언트 생성\n",
      "aws_docs_client = MCPClient(\n",
      "    lambda: stdio_client(StdioServerParameters(command=\"uvx\", args=[\"awslabs.aws-documentation-mcp-server@latest\"]))\n",
      ")\n",
      "\n",
      "with aws_docs_client:\n",
      "    agent = Agent(tools=aws_docs_client.list_tools_sync())\n",
      "    response = agent(\"Tell me about Amazon Bedrock and how to use it with Python\")\n",
      "```\n",
      "\n",
      "## 6. 실제 적용 사례 및 활용 분야\n",
      "\n",
      "### 실제 적용 사례\n",
      "\n",
      "1. **Amazon Q Developer**: 소프트웨어 개발을 위한 AI 어시스턴트\n",
      "2. **AWS Glue**: 데이터 통합 및 ETL 프로세스 자동화\n",
      "3. **VPC Reachability Analyzer**: 네트워크 연결 분석\n",
      "4. **AWS Transform for .NET**: 레거시 .NET 애플리케이션 분석, 현대화 전략 계획, 코드 변환 실행\n",
      "\n",
      "### 주요 활용 분야\n",
      "\n",
      "1. **자율 에이전트 시나리오**: 인간 개입 없이 복잡한 작업 수행\n",
      "2. **AWS 인프라 기반 조직**: AWS 서비스와 네이티브 통합 활용\n",
      "3. **엔터프라이즈급 시스템**: 보안, 확장성, 규정 준수 기능이 필요한 환경\n",
      "4. **유연한 모델 선택 프로젝트**: 다양한 모델 제공업체 간 선택이 필요한 경우\n",
      "5. **AWS 통합 사용 사례**: 기존 AWS 워크플로 및 리소스와 긴밀한 통합 필요 시\n",
      "\n",
      "### 산업별 적용\n",
      "\n",
      "1. **소프트웨어 개발**: 코드 생성, 디버깅, 문서화 자동화\n",
      "2. **고객 서비스**: 지능형 챗봇 및 자동화된 지원 시스템\n",
      "3. **데이터 분석**: 데이터 처리, 분석, 인사이트 생성 자동화\n",
      "4. **IT 운영**: 시스템 모니터링, 문제 해결, 자동화된 대응\n",
      "5. **콘텐츠 생성**: 마케팅 콘텐츠, 보고서, 문서 자동 생성\n",
      "\n",
      "## 7. 미래 전망 및 결론\n",
      "\n",
      "### 미래 전망\n",
      "\n",
      "1. **커뮤니티 성장**: Accenture, Anthropic, Meta, PwC 등 여러 기업의 지원과 기여로 계속 성장 예상\n",
      "2. **기능 확장**: 더 다양한 모델과 도구 지원, 고급 에이전트 조정 기능, 성능 최적화 발전 예상\n",
      "3. **산업 채택 증가**: AI 에이전트의 중요성 증가에 따른 Strands 도입 확대 예상\n",
      "4. **멀티모달 기능 강화**: 텍스트 외에 이미지, 오디오, 비디오 등 다양한 모달리티 지원 강화\n",
      "5. **에이전트 간 협업 기능**: 다중 에이전트 시스템에서의 협업과 조정 기능 발전 예상\n",
      "\n",
      "### 결론\n",
      "\n",
      "Strands Agents는 AI 에이전트 개발의 복잡성을 크게 낮추고, 개발자들이 최신 모델의 강력한 기능을 더 쉽게 활용할 수 있도록 하는 중요한 진전입니다. 모델 중심 접근 방식은 LLM의 자연적인 추론 능력을 활용하여 복잡한 오케스트레이션 코드 없이도 강력한 에이전트를 구축할 수 있게 해줍니다.\n",
      "\n",
      "AWS 서비스와의 긴밀한 통합과 다양한 모델 제공업체 지원을 통해 Strands는 다양한 사용 사례에 적용할 수 있는 유연성을 제공합니다. 오픈 소스 프로젝트로서 커뮤니티의 지속적인 발전과 지원을 받을 수 있는 장점도 있습니다.\n",
      "\n",
      "그러나 Strands의 모델 중심 접근 방식은 사용하는 모델의 품질과 능력에 크게 의존하므로, 적절한 모델 선택과 구성이 중요합니다. 또한 AWS 생태계에 최적화되어 있어, 다른 클라우드 제공업체를 사용하는 경우 일부 기능의 활용이 제한될 수 있습니다.\n",
      "\n",
      "전반적으로 Strands Agents는 AI 에이전트 개발을 민주화하고 가속화하는 데 큰 기여를 하고 있으며, 향후 AI 에이전트 생태계에서 중요한 역할을 계속할 것으로 예상됩니다."
     ]
    }
   ],
   "source": [
    "stdio_mcp_web = MCPClient(lambda: stdio_client(\n",
    "    StdioServerParameters(command=\"npx\", args=[\"-y\", \"@pinkpixel/web-scout-mcp\"])\n",
    "))\n",
    "\n",
    "stdio_mcp_thinking = MCPClient(lambda: stdio_client(\n",
    "    StdioServerParameters(command=\"npx\", args=[\"-y\", \"@modelcontextprotocol/server-sequential-thinking\"])\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "with stdio_mcp_web:\n",
    "    tools_web = stdio_mcp_web.list_tools_sync() # get tools from MCP\n",
    "    \n",
    "    with stdio_mcp_thinking:\n",
    "        tools_thinking = stdio_mcp_thinking.list_tools_sync() # get tools from MCP\n",
    "        \n",
    "        tools = tools_web + tools_thinking\n",
    "        agent = Agent(tools=tools)\n",
    "        results = agent(\"최신 AI Agent에 대한 내용을 탐색/분석하고, Strand Agent의 특징과 장단점, 사용법 등 상세보고서를 작성해 줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a5346e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 최신 AI Agent와 Strand Agents 상세 보고서\n",
      "\n",
      "## 1. AI 에이전트(Agent)의 개념과 배경\n",
      "\n",
      "AI 에이전트는 사용자의 목표를 달성하기 위해 데이터를 분석하고, 스스로 판단하며, 실제 행동을 수행하는 자율적 인공지능 시스템입니다. 기존의 생성형 AI가 콘텐츠 생성에 집중했다면, AI 에이전트는 문제 해결과 작업 실행까지 포괄합니다. \n",
      "\n",
      "**핵심 특징:**\n",
      "- **자율성**: 인간의 개입 없이도 작업을 완료할 수 있는 능력\n",
      "- **추론 및 계획 능력**: 복잡한 문제에 대한 단계별 접근 가능\n",
      "- **도구 사용 능력**: 다양한 외부 도구와 API를 활용하여 작업 수행\n",
      "\n",
      "최근 몇 년간 LLM(대규모 언어 모델)의 발전으로 인해 AI 에이전트 기술도 크게 발전했으며, 특히 ReAct(Reasoning and Acting) 논문 이후로 LLM이 추론하고, 계획하며, 환경에서 행동을 취할 수 있게 되었습니다.\n",
      "\n",
      "## 2. Strands Agents 소개\n",
      "\n",
      "Strands Agents는 AWS에서 출시한 오픈 소스 AI Agent SDK로, 모델 중심(model-driven) 접근 방식을 사용해 코드 몇 줄만으로 AI 에이전트를 구축하고 실행할 수 있게 해줍니다. 이미 Amazon Q Developer, AWS Glue, VPC Reachability Analyzer 등 여러 AWS 내부 팀에서 Strands Agents를 프로덕션에 사용하고 있습니다.\n",
      "\n",
      "### 핵심 구성 요소\n",
      "\n",
      "Strands Agents에서 AI 에이전트는 세 가지 핵심 요소로 구성됩니다:\n",
      "\n",
      "1. **모델(Model)**: 에이전트의 '두뇌' 역할을 하는 LLM\n",
      "   - Amazon Bedrock, Anthropic, Ollama, Meta 등 다양한 제공업체 모델 지원\n",
      "   - 추론 및 도구 사용 기능을 갖춘 모델 활용\n",
      "\n",
      "2. **도구(Tools)**: 에이전트가 작업을 수행하기 위해 사용하는 기능들\n",
      "   - Model Context Protocol(MCP) 서버를 통해 수천 개의 기존 도구 제공\n",
      "   - 파일 조작, API 요청, AWS API 상호작용 등을 위한 20개 이상의 사전 구축 도구\n",
      "   - Python 함수를 `@tool` 데코레이터로 쉽게 도구화 가능\n",
      "\n",
      "3. **프롬프트(Prompt)**: 에이전트에게 주어지는 작업을 정의하는 자연어 지시문\n",
      "   - 일반 프롬프트: 최종 사용자의 질문이나 작업 요청\n",
      "   - 시스템 프롬프트: 에이전트의 일반적인 행동 및 지침 정의\n",
      "\n",
      "### Agentic Loop (에이전트 루프)\n",
      "\n",
      "Strands의 핵심은 '에이전틱 루프(agentic loop)'라는 반복 과정으로, 이 과정에서 에이전트는 모델과 도구를 사용하여 주어진 작업을 완료합니다:\n",
      "\n",
      "1. LLM에 프롬프트와 에이전트 컨텍스트, 도구 설명을 제공\n",
      "2. LLM은 자연어로 응답하거나, 단계를 계획하거나, 이전 단계에 반성하거나, 도구를 선택\n",
      "3. LLM이 도구를 선택하면 Strands가 이를 실행하고 결과를 LLM에 다시 제공\n",
      "4. LLM이 작업을 완료할 때까지 이 과정 반복\n",
      "\n",
      "## 3. Strands Agents의 주요 특징과 기능\n",
      "\n",
      "1. **경량 및 유연한 설계**\n",
      "   - 간단하면서도 완전히 사용자 정의 가능한 에이전트 루프\n",
      "   - 복잡한 오케스트레이션 없이도 효과적인 에이전트 구현\n",
      "\n",
      "2. **모델 독립적(Model Agnostic)**\n",
      "   - Amazon Bedrock, Anthropic, LiteLLM, Llama, Ollama, OpenAI, Writer 등 지원\n",
      "   - 사용자 정의 모델 제공업체 구현 가능\n",
      "\n",
      "3. **고급 기능**\n",
      "   - 다중 에이전트 시스템: 여러 에이전트 간 협업 가능\n",
      "   - 자율 에이전트: 최소한의 인간 개입으로 복잡한 작업 수행\n",
      "   - 스트리밍 지원: 실시간 응답 처리\n",
      "\n",
      "4. **내장 MCP(Model Context Protocol)**\n",
      "   - MCP 서버에 대한 네이티브 지원\n",
      "   - 수천 개의 미리 구축된 도구에 접근 가능\n",
      "\n",
      "5. **AWS 서비스 통합**\n",
      "   - Amazon Bedrock, AWS Lambda, AWS Step Functions 등과 원활한 연결\n",
      "   - AWS 인프라를 기반으로 한 조직에 최적화\n",
      "\n",
      "6. **멀티모달 기능**\n",
      "   - 텍스트, 음성, 이미지 처리 등 여러 모달리티 지원\n",
      "\n",
      "7. **풍부한 도구 생태계**\n",
      "   - AWS 서비스 상호 작용을 위한 다양한 도구 세트\n",
      "   - 사용자 정의 도구 확장성\n",
      "\n",
      "## 4. Strands Agents의 장단점\n",
      "\n",
      "### 장점\n",
      "\n",
      "1. **단순성과 빠른 개발**\n",
      "   - 복잡한 오케스트레이션 코드 없이 몇 줄의 코드만으로 에이전트 구축\n",
      "   - 개발 시간 대폭 단축 (몇 달에서 며칠/몇 주로)\n",
      "\n",
      "2. **유연성**\n",
      "   - 다양한 LLM과 도구를 지원하여 다양한 사용 사례에 적용 가능\n",
      "   - 사용자 정의 도구 및 모델 제공업체 구현 가능\n",
      "\n",
      "3. **확장성**\n",
      "   - 간단한 대화형 어시스턴트부터 복잡한 자율 워크플로우까지 확장\n",
      "   - 로컬 개발에서 프로덕션 배포까지 지원\n",
      "\n",
      "4. **최신 모델의 능력 활용**\n",
      "   - 최신 LLM의 발전된 추론 및 도구 사용 능력 최대한 활용\n",
      "   - 모델의 자연적인 추론 능력에 의존하여 복잡한 코딩 감소\n",
      "\n",
      "5. **AWS 서비스 통합**\n",
      "   - AWS 인프라 기반 조직에 원활한 통합 제공\n",
      "   - 기존 AWS 리소스와의 효율적인 연동\n",
      "\n",
      "6. **오픈 소스**\n",
      "   - 커뮤니티 기반 개발과 지원\n",
      "   - 필요에 따른 맞춤 설정 가능\n",
      "\n",
      "### 단점\n",
      "\n",
      "1. **모델 의존성**\n",
      "   - 모델 중심 접근 방식은 사용하는 LLM의 능력에 크게 의존\n",
      "   - 모델 품질이 낮으면 에이전트 성능도 제한될 수 있음\n",
      "\n",
      "2. **AWS 친화적 설계**\n",
      "   - AWS 서비스와의 통합에 초점\n",
      "   - 다른 클라우드 제공업체 사용 조직에서는 일부 기능 활용 제한\n",
      "\n",
      "3. **복잡한 작업의 신뢰성**\n",
      "   - 매우 복잡한 작업의 경우, 모델 중심 접근이 전통적 워크플로우보다 예측 가능성 낮을 수 있음\n",
      "   - 결정적인 결과가 필요한 경우 추가 검증 필요\n",
      "\n",
      "4. **학습 곡선**\n",
      "   - 기존 프레임워크에서 전환하는 개발자들에게 새로운 패러다임 학습 필요\n",
      "\n",
      "## 5. Strands Agents 사용 방법\n",
      "\n",
      "### 설치\n",
      "\n",
      "```bash\n",
      "# 가상 환경 생성 및 활성화\n",
      "python -m venv .venv\n",
      "source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n",
      "\n",
      "# Strands 및 도구 설치\n",
      "pip install strands-agents strands-agents-tools\n",
      "```\n",
      "\n",
      "### 기본 사용법\n",
      "\n",
      "```python\n",
      "from strands import Agent\n",
      "from strands_tools import calculator\n",
      "\n",
      "# 기본 에이전트 생성 (기본적으로 Amazon Bedrock의 Claude 4 Sonnet 모델 사용)\n",
      "agent = Agent(tools=[calculator])\n",
      "\n",
      "# 에이전트에게 질문하기\n",
      "response = agent(\"What is the square root of 1764\")\n",
      "```\n",
      "\n",
      "### 파이썬 기반 도구 생성\n",
      "\n",
      "```python\n",
      "from strands import Agent, tool\n",
      "\n",
      "@tool\n",
      "def word_count(text: str) -> int:\n",
      "    \"\"\"Count words in text.\n",
      "    This docstring is used by the LLM to understand the tool's purpose.\n",
      "    \"\"\"\n",
      "    return len(text.split())\n",
      "\n",
      "agent = Agent(tools=[word_count])\n",
      "response = agent(\"How many words are in this sentence?\")\n",
      "```\n",
      "\n",
      "### 다양한 모델 제공업체 사용\n",
      "\n",
      "```python\n",
      "# Bedrock\n",
      "from strands.models import BedrockModel\n",
      "bedrock_model = BedrockModel(\n",
      "    model_id=\"us.amazon.nova-pro-v1:0\",\n",
      "    temperature=0.3,\n",
      "    streaming=True,  # 스트리밍 활성화/비활성화\n",
      ")\n",
      "agent = Agent(model=bedrock_model)\n",
      "\n",
      "# Ollama (로컬 개발용)\n",
      "from strands.models.ollama import OllamaModel\n",
      "ollama_model = OllamaModel(\n",
      "    host=\"http://localhost:11434\",\n",
      "    model_id=\"llama3\"\n",
      ")\n",
      "agent = Agent(model=ollama_model)\n",
      "\n",
      "# Llama API\n",
      "from strands.models.llamaapi import LlamaAPIModel\n",
      "llama_model = LlamaAPIModel(\n",
      "    model_id=\"Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
      ")\n",
      "agent = Agent(model=llama_model)\n",
      "\n",
      "# Cohere (OpenAI 호환성 레이어 사용)\n",
      "from strands.models.openai import OpenAIModel\n",
      "model = OpenAIModel(\n",
      "    client_args={\n",
      "        \"api_key\": \"<COHERE_API_KEY>\",\n",
      "        \"base_url\": \"https://api.cohere.ai/compatibility/v1\",\n",
      "        # Cohere 호환성 엔드포인트\n",
      "    },\n",
      "    model_id=\"command-a-03-2025\",\n",
      "    params={\n",
      "        \"stream_options\": None\n",
      "    }\n",
      ")\n",
      "agent = Agent(model=model)\n",
      "```\n",
      "\n",
      "### MCP 서버 통합\n",
      "\n",
      "```python\n",
      "from strands import Agent\n",
      "from strands.tools.mcp import MCPClient\n",
      "from mcp import stdio_client, StdioServerParameters\n",
      "\n",
      "# AWS 문서에 접근하는 MCP 클라이언트 생성\n",
      "aws_docs_client = MCPClient(\n",
      "    lambda: stdio_client(StdioServerParameters(command=\"uvx\", args=[\"awslabs.aws-documentation-mcp-server@latest\"]))\n",
      ")\n",
      "\n",
      "with aws_docs_client:\n",
      "    agent = Agent(tools=aws_docs_client.list_tools_sync())\n",
      "    response = agent(\"Tell me about Amazon Bedrock and how to use it with Python\")\n",
      "```\n",
      "\n",
      "## 6. 실제 적용 사례 및 활용 분야\n",
      "\n",
      "### 실제 적용 사례\n",
      "\n",
      "1. **Amazon Q Developer**: 소프트웨어 개발을 위한 AI 어시스턴트\n",
      "2. **AWS Glue**: 데이터 통합 및 ETL 프로세스 자동화\n",
      "3. **VPC Reachability Analyzer**: 네트워크 연결 분석\n",
      "4. **AWS Transform for .NET**: 레거시 .NET 애플리케이션 분석, 현대화 전략 계획, 코드 변환 실행\n",
      "\n",
      "### 주요 활용 분야\n",
      "\n",
      "1. **자율 에이전트 시나리오**: 인간 개입 없이 복잡한 작업 수행\n",
      "2. **AWS 인프라 기반 조직**: AWS 서비스와 네이티브 통합 활용\n",
      "3. **엔터프라이즈급 시스템**: 보안, 확장성, 규정 준수 기능이 필요한 환경\n",
      "4. **유연한 모델 선택 프로젝트**: 다양한 모델 제공업체 간 선택이 필요한 경우\n",
      "5. **AWS 통합 사용 사례**: 기존 AWS 워크플로 및 리소스와 긴밀한 통합 필요 시\n",
      "\n",
      "### 산업별 적용\n",
      "\n",
      "1. **소프트웨어 개발**: 코드 생성, 디버깅, 문서화 자동화\n",
      "2. **고객 서비스**: 지능형 챗봇 및 자동화된 지원 시스템\n",
      "3. **데이터 분석**: 데이터 처리, 분석, 인사이트 생성 자동화\n",
      "4. **IT 운영**: 시스템 모니터링, 문제 해결, 자동화된 대응\n",
      "5. **콘텐츠 생성**: 마케팅 콘텐츠, 보고서, 문서 자동 생성\n",
      "\n",
      "## 7. 미래 전망 및 결론\n",
      "\n",
      "### 미래 전망\n",
      "\n",
      "1. **커뮤니티 성장**: Accenture, Anthropic, Meta, PwC 등 여러 기업의 지원과 기여로 계속 성장 예상\n",
      "2. **기능 확장**: 더 다양한 모델과 도구 지원, 고급 에이전트 조정 기능, 성능 최적화 발전 예상\n",
      "3. **산업 채택 증가**: AI 에이전트의 중요성 증가에 따른 Strands 도입 확대 예상\n",
      "4. **멀티모달 기능 강화**: 텍스트 외에 이미지, 오디오, 비디오 등 다양한 모달리티 지원 강화\n",
      "5. **에이전트 간 협업 기능**: 다중 에이전트 시스템에서의 협업과 조정 기능 발전 예상\n",
      "\n",
      "### 결론\n",
      "\n",
      "Strands Agents는 AI 에이전트 개발의 복잡성을 크게 낮추고, 개발자들이 최신 모델의 강력한 기능을 더 쉽게 활용할 수 있도록 하는 중요한 진전입니다. 모델 중심 접근 방식은 LLM의 자연적인 추론 능력을 활용하여 복잡한 오케스트레이션 코드 없이도 강력한 에이전트를 구축할 수 있게 해줍니다.\n",
      "\n",
      "AWS 서비스와의 긴밀한 통합과 다양한 모델 제공업체 지원을 통해 Strands는 다양한 사용 사례에 적용할 수 있는 유연성을 제공합니다. 오픈 소스 프로젝트로서 커뮤니티의 지속적인 발전과 지원을 받을 수 있는 장점도 있습니다.\n",
      "\n",
      "그러나 Strands의 모델 중심 접근 방식은 사용하는 모델의 품질과 능력에 크게 의존하므로, 적절한 모델 선택과 구성이 중요합니다. 또한 AWS 생태계에 최적화되어 있어, 다른 클라우드 제공업체를 사용하는 경우 일부 기능의 활용이 제한될 수 있습니다.\n",
      "\n",
      "전반적으로 Strands Agents는 AI 에이전트 개발을 민주화하고 가속화하는 데 큰 기여를 하고 있으며, 향후 AI 에이전트 생태계에서 중요한 역할을 계속할 것으로 예상됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(results.message['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef6fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c1423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8532eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c36f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
